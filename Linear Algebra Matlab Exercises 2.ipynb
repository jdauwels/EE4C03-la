{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "EE4C03 \r\n",
    "===\r\n",
    "Statistical Digital Signal Processing and Modeling\r\n",
    "============\r\n",
    "\r\n",
    "# Computer Exercise 1b\r\n",
    "\r\n",
    "Note: Interact with Octave/Matlab in Notebook. All commands are interpreted by Octave/Matlab. Help on commands is available using the `%help` magic or using `?` with a command."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Projections\n",
    "\n",
    "If $\\bf v$ is a vector, then a projection onto $\\bf v$ is the matrix\n",
    "\n",
    "$$\n",
    "    {\\bf P}= \\frac{1}{{\\bf v}^H{\\bf v}}{\\bf v}{\\bf v}^{H}\n",
    "$$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### a. Generate a random $5 \\times 1$ vector"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "% modify code here\r\n",
    "v = randn(1,1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### b. Construct the Projection matrix $\\bf P$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "% modify code here\r\n",
    "% hint: v^H = v'\r\n",
    "% hint: notice that v'*v is a scalar\r\n",
    "% hint: x./y does element-wise division\r\n",
    "% advice: For Matlab/Octave for defining symmetric matrices is\r\n",
    "% encouraged to use paranthesis, e.g., (x*x')\r\n",
    "P = eye(1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "% caution:!! \r\n",
    "% P2 = v*inv(v'*v)*v'; might work! but...Matlab/Octave do...shady things\r\n",
    "% extra: what could be the \"numerical\" problem that you might encounter later?"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "&nbsp;&nbsp; Check the properties of an (orthogonal) projection matrix, i.e.,\n",
    "\n",
    "$$\n",
    "    {\\bf P P = P}\\\\\n",
    "    {\\bf P}^H = \\bf P\n",
    "$$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "% add code here\r\n",
    "% [code]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "&nbsp;&nbsp; Also checks that it leaves $\\bf v$ intact: $\\bf Pv = v$."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "% add code here\r\n",
    "% [code]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### c. Do an eigenvalue decomposition of $\\bf P$, i.e., ${\\bf P = U\\Lambda U}^H$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "% add code here\r\n",
    "% hint: use 'help eig' to see the sintaxis\r\n",
    "% [U,Lambda] = [code]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "&nbsp;&nbsp; Look at $\\bf \\Lambda$. What is the rank of $\\bf P$?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "% check your answer using: \r\n",
    "% 'rank' function, type 'help rank' to know more about the command\r\n",
    "% or by plotting the eigenvalues, e.g., 'plot(diag(E))'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "&nbsp;&nbsp; Note that the eigenvalues are not necessarily sorted (because generally they may be complex). We can find the sorting order and correct for it:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "% uncomment code below to sort (remove '%' in front of code)\r\n",
    "% Warning: Check that the name of the variable match the ones you used!!\r\n",
    "%[~,index] = sort(diag(Lambda),'descend')\r\n",
    "%U = U(:, index); Lambda = Lambda(index,index)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "&nbsp;&nbsp; Check that you still have the same $\\bf P$!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "% construct Pnew using the sorted eigenvectors and eigenvalues, i.e., U and Lambda\r\n",
    "%Pnew = [code]\r\n",
    "%disp(Pnew)\r\n",
    "%disp(P)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### d. Split ${\\bf U} = [{\\bf u}_1, {\\bf U}_2]$ where ${\\bf u}_2$ is the first column of $\\bf U$, and ${\\bf U}_2$ are the remaining columns. How does ${\\bf u}_1$ relate to ${\\bf v}$? And ${\\bf U}_2$?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "% add code\r\n",
    "% u1 = U([code])\r\n",
    "% U2 = U([code])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "&nbsp;&nbsp; Check that ${\\bf u}_1 = \\alpha{\\bf v}$, and ${\\bf U}_2^H{\\bf v} = \\bf 0$. Also check that ${\\bf PU}_2 = \\bf 0$. Why do these properties hold?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "% add code\r\n",
    "% [code] to check scaling property of u_1 and v\r\n",
    "% [code] to check orthogonality property of U_2 with v\r\n",
    "% [code] to check orthogonality property of P and U_2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### e. Define the projection on the orthogonal complement of $\\bf v$,\n",
    "\n",
    "$$\n",
    "    {\\bf P}^{\\perp} = \\bf I - P.\n",
    "$$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "% add code\r\n",
    "% Pperp = [code]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "&nbsp;&nbsp; Check that ${\\bf P}^{\\perp} = {\\bf U}_2{\\bf U}_2^H$. Why is that?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "% add code\r\n",
    "% [code] to check property "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "&nbsp;&nbsp; Why is ${\\bf U}_2{\\bf U}_2^H$ a projection? Why don't we have to write ${\\bf U}_2({\\bf U}_2^H{\\bf U}_2)^{-1}{\\bf U}_2^H$?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "% hint: check your answer trying U2'*U2\r\n",
    "% [code]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### f. Generate a random vector $\\bf x$. Split $\\bf x$ into ${\\bf x}_{\\rm par}:=\\bf Px$ and ${\\bf x}_{\\rm perp} := {\\bf P}^\\perp{\\bf x}$."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "% add code\r\n",
    "% x = [code]\r\n",
    "% xpar = [code]\r\n",
    "% xperp = [code]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "&nbsp;&nbsp; Verify hat ${\\bf x = Px + P}^{\\perp}{\\bf x}$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "% add code\r\n",
    "% [code]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "&nbsp;&nbsp; What is the geometric picture that goes with this?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "*Extra:* If you want, you can generalize this exercise to a matrix $\\bf V$ consiting of $2$ (or more) random columns. This works as long as $\\bf V$ is a 'tall' matrix (more rows than columns)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Singular value decomposition"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The singular value decomposition (SVD) is closely related to an eigenvalue decomposition, but is more general: it exists for any matrix (can be rectangular). It will be often used in future\n",
    "courses in the MSc (you might see it referred to as PCA as well). A short intro follows in Appendix A of the PDF."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### a. Create a matlab function to construct a (complex) vector ${\\bf a}(\\theta)$:\n",
    "\n",
    "` a = @(theta) [code]` (this is what is called inline function)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "where $\\theta$ is an angle (in radians or degrees) and $M$ is the dimension of $\\bf a$\n",
    "\n",
    "$$\n",
    "    {\\bf a}(\\theta) = \\begin{bmatrix}\n",
    "        1 \\\\ e^{-j\\phi} \\\\ e^{-j2\\phi} \\\\ \\vdots \\\\ e^{-j(M-1)\\phi}\n",
    "    \\end{bmatrix}, \\;\\; \\phi = \\pi\\sin(\\theta),\\; j =\\sqrt{-1}\n",
    "$$\n",
    "\n",
    "This vector is called the direction vector in array signal processing (see the ET4147 course later this year). The entries are phases corresponding to propagation delays experienced by a plane wave signals hitting an antenna array, and it occurs in communication (antenna arrays), radar, radio astronomy, ultrasound, and MRI."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "% hint: an inline function, for example, to compute pi*sin(theta) is\r\n",
    "phi = @(theta) pi*sin(theta);\r\n",
    "% phi should be 'zero' for theta = pi\r\n",
    "disp(phi(pi))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   3.8473e-16\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "% use the above inline function to make an inline function for a(theta)\r\n",
    "% a = @(theta) [code]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "&nbsp;&nbsp; Let $A = [{\\bf a}(\\theta_1), {\\bf a}(\\theta_2)]$ where $\\theta_1 = 0^o$, $\\theta_2 = 30^o$ (convert this to radians if needed). Let $\\bf S$ be a random matrix with $2$ rows and $N = 20$ samples,"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "% add code\r\n",
    "% generate A matrix\r\n",
    "% a_1 = a([code])\r\n",
    "% a_2 = a([code])\r\n",
    "% A = [code]\r\n",
    "% generate random matrix\r\n",
    "% hint: use 'randn' function\r\n",
    "% S = [code]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "&nbsp;&nbsp; Then generate a data matrix\n",
    "\n",
    "$$\n",
    "    {\\bf X = AS}\n",
    "$$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "% add code\r\n",
    "% X = [code]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "&nbsp;&nbsp; What do you think is the rank of $\\bf X$?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### b. Construct ${\\bf R = XX}^H$. What is the rank of $\\bf R$?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "% add code\r\n",
    "% R = [code]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "&nbsp;&nbsp; In the course we will see this matrix very often (correlation matrix)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### c. Compute the SVD of ${\\bf X = U\\Sigma V}^H$. Also compute the eigenvalue decomposition of ${\\bf R = Q\\Lambda Q}^H$."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "% add code\r\n",
    "% hint: use 'help svd' to see the sintaxis of SVD\r\n",
    "% [U,Sigma, V] = [code]\r\n",
    "% [Q,Lambda] = [code]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### d. Compare $\\bf \\Sigma$ to $\\bf \\Lambda$, verify ${\\bf \\Sigma}^2 = \\bf \\Lambda$, up to _sorting_. What is the rank of $\\bf X$, as judged from $\\bf\\Sigma$? Very that $\\bf R$ is a positive matrix: its eigenvalues are _non-negative_."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "% try something if needed to corroborate your conclusions.\r\n",
    "% add code"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "&nbsp;&nbsp; Compare $\\bf U$ to $\\bf Q$: show that they are the same, up to a permutation of the columns and a (complex) scaling of the columns. You can do that by checking ${\\bf U}^H\\bf Q$."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "% add code\r\n",
    "% [code]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### e. Suppose we compute an SVD of $\\bf R$."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "% add code\r\n",
    "% [U1,Sigma1,V1] = [code]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "&nbsp;&nbsp; Does that give the same results as the eigenvalue decomposition of $\\bf R$? What is the relation between ${\\bf U}_1$ and ${\\bf V}_1$?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "% add code\r\n",
    "% try, for example, U_1'*V1 to corroborate your conclusions"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### f. Plot the singular values:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "% uncomment the following commands\r\n",
    "% plot(diag(Sigma1),'+');\r\n",
    "% hold on"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### g. Now, take $\\theta_2 = 5^o$. Regenerate, $\\bf X$, recompute the SVD, and plot the new singular values (use a different color)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "% add code here\r\n",
    "% X = [code]\r\n",
    "% R = [code]\r\n",
    "% [U, Sigma2, V] = [code]\r\n",
    "% [plot Sigma1]\r\n",
    "% hold on\r\n",
    "% [plot Sigma2]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### h. Now, add a bit of (complex) noise to $\\bf X$, i.e., write\n",
    "&nbsp;&nbsp;`X1 = X + 0.01*( randn(size(X)) + 1i*randn(size(X)) );`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "% add code\r\n",
    "% X1 = [code]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "&nbsp;&nbsp; Compute the singular values of ${\\bf X}_1$, and plot them in the same plot (use a different color). What do you observe?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "% add code\r\n",
    "% [U1, Sigma1, V1] = [code]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "&nbsp;&nbsp; Compare ${\\bf U}$ to ${\\bf U}_1$ using ${\\bf U}^H{\\bf U}_1$. We would want to conclude that the first two singular vectors have hardly changed (and span the same space), while the other $3$ columns might be quite different, but still span the same space. How can you conclude that by looking at ${\\bf U}^H{\\bf U}_1$?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "% add code\r\n",
    "% inspect U'*U1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "&nbsp;&nbsp; We will see applications of this when we discuss the MUSIC algorithm at the end of the course."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### i. Note the size of $\\bf \\Sigma$ and of $\\bf V$. In fact, $\\bf X$ and $\\bf \\Sigma$ have the same size, and $\\bf \\Sigma$ contains many columns with just zeros: not very efficient!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "&nbsp;&nbsp; Alternatively, we almost always compute the ’economy-size SVD’,\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;`[U,Sigma,V] = svd(X,'econ')`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "% add code for economy size SVD\r\n",
    "% [U, Sigma, V] = [code]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "&nbsp;&nbsp; Check the size of the resulting matrices. Check that still ${\\bf X} = {\\bf U\\Sigma V}^H$. Check that ${\\bf V}^H{\\bf V = I}$."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "% add code\r\n",
    "% hint: to check size use command 'size()'\r\n",
    "% [code]\r\n",
    "% [code] to check X\r\n",
    "% [code] to check self inner product of V"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "&nbsp;&nbsp; Now $\\bf\\Sigma$ is square, and ${\\bf V}$ is _rectangular_. It _cannot_ be a _unitary_ matrix anymore. We\n",
    "usually are not interested in the columns that were dropped."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "If $\\bf X$ was tall, then the economy-size SVD will result in $\\bf U$ being truncated to the size of ${\\bf X}$ (with\n",
    "${\\bf U}^H{\\bf U = I})$, while now $\\bf V$ remains square. We’ll see an example in the next section."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Convolution and equalization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The matrix equation corresponding to a convolution $y[n] = x[n] \\ast h[n] = \\displaystyle\\sum_{k=0}^{L-1} h[k] x[n-k]$ is \n",
    "$$\n",
    "   \\bf y = \\bf H \\bf x \\quad \\Leftrightarrow \\quad\n",
    "   \\begin{bmatrix}\n",
    "       \\fbox{$y[0]$} \\\\ \n",
    "       y[1] \\\\\n",
    "       y[2] \\\\\n",
    "       \\vdots \\\\ \n",
    "       \\vdots \\\\\n",
    "       \\vdots \\\\\n",
    "       \\vdots \\\\\n",
    "       y[N_y-1] \\end{bmatrix}\n",
    "   =\n",
    "   \\begin{bmatrix}\n",
    "   \\fbox{$h[0]$} &  & & {\\textbf 0}\\\\\n",
    "   h[1]   & h[0] \\\\\n",
    "   h[2]   & h[1]   & \\ddots & \\\\\n",
    "   \\vdots & h[2]   & \\ddots & h[0] \\\\\n",
    "   h[L-1] & \\vdots & \\ddots & h[1] \\\\\n",
    "          & h[L-1] & \\ddots & h[2] \\\\\n",
    "          &        & \\ddots & \\vdots \\\\\n",
    "   {\\textbf 0}  &  &        & h[L-1] \n",
    "   \\end{bmatrix}\n",
    "   \\begin{bmatrix}\n",
    "      \\fbox{$x[0]$} \\\\ \\vdots \\\\ x[N_x-1] \\end{bmatrix}\n",
    "\\label{eq:conv} \\tag{1}\n",
    "$$\n",
    "   \n",
    "where the ``box'' indicates the location of time-index 0,\n",
    "   $L$ is the channel length (assuming an FIR channel), \n",
    "   $N_x$ is the length of  the input sequence (subsequent samples are \n",
    "   supposed to be zero), and $N_y$ is the length of the output sequence\n",
    "   (ignoring the other samples).\n",
    "   Note that $\\bf H$ has size $N_x+L-1 \\times N_x$ so that $N_y = N_x + L-1$.\n",
    "   $\\bf H$ is always tall. \n",
    "\n",
    "   $\\bf H$ has a Toeplitz structure: constant along diagonals. That structure\n",
    "   always appears when we have shift invariance--we will see it often\n",
    "   during the course."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### a. Take a simple channel, `h = [1 2 3]'`, and input signal,  `x = randn(4,1)`. Generate `y[n]` using  `y = filter(h,1,x)`. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "% add code here\r\n",
    "% [code]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Also create the matrices in equation (1) and check that $\\bf y = \\bf H \\bf x$.  In matlab, you can use the function `toeplitz`:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "% add code here\r\n",
    "% hint: H = toeplitz([h; 0; 0; 0], [h(1) 0 0 0])\r\n",
    "% [code]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### b. Check $\\bf H^H \\bf H$ and $\\bf H \\bf H^H$. Are these Toeplitz matrices? "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "% add code here\r\n",
    "% [code]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    " Suppose we observe $\\bf y$ and know the channel $\\bf h$. \n",
    "The input signal can be estimated by taking a left inverse $\\bf H^\\dagger$ of $\\bf H$, such that $\\bf H^\\dagger \\bf H = \\bf I$. We can usually take\n",
    "\n",
    "$$\n",
    "       \\bf H^\\dagger = (\\bf H^H \\bf H)^{-1} \\bf H^H\n",
    "$$\n",
    "where, for now, we assume that $\\bf H^H \\bf H$ is invertible. This results in\n",
    "\n",
    "$$\n",
    "    \\hat{\\bf x} = \\bf H^\\dagger \\bf y = (\\bf H^H \\bf H)^{-1} \\bf H^H \\bf y \\,.\n",
    "\\label{eq:loc:sourceestim1}\n",
    "$$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### c. Construct $\\bf H^\\dagger$. Verify that $\\bf H^\\dagger \\bf H = \\bf I$ and that $\\bf H \\bf H^\\dagger$ is a projection.  Explain why this is the case."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "% add code here\r\n",
    "% [code]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### d. Compute the singular values of $\\bf H$ and of $\\bf H^\\dagger$.  What do you notice?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "% add code here\r\n",
    "% [code]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### e. Verify in matlab that  $\\hat{\\bf x} = \\bf H^\\dagger \\bf y$ gives back the original signal (noiseless case)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "% add code here\r\n",
    "% [code]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Equalization: a rank-deficient case"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Suppose that, in equation (1), we start to measure the\n",
    "    output only after the input signal has stopped (e.g., in communication,\n",
    "    we can listen only after we stopped transmitting).\n",
    "    Also, suppose that the channel is generated by an\n",
    "    auto-regressive (AR) model:\n",
    "$$\n",
    "    H(z) = \\frac{1}{1-a z^{-1}}\n",
    "    \\qquad\\Leftrightarrow\\qquad\n",
    "    \\mathbf{h} = [1,\\; a,\\; a^2,\\; \\cdots]^T \\,.\n",
    "$$\n",
    "\n",
    "Since the impulse response is infinitely long, we obtain\n",
    "\n",
    "$$\n",
    "  \\mathbf{y}  = \\mathbf{H} \\mathbf{x} \\quad \\Leftrightarrow \\quad\n",
    "   \\begin{bmatrix}\n",
    "       y[N_x-1] \\\\ y[N_x] \\\\ y[N_x+1] \\\\ \\vdots \\\\ \\vdots \\\\ y[N_y-1] \\end{bmatrix} = \n",
    "       \\begin{bmatrix} h[N_x-1] & \\cdots & h[1] & h[0] \\\\ h[N_x]   & \\cdots & h[2] & h[1] \\\\\\vdots   & \\vdots & h[3] & h[2] \\\\ \\vdots   & \\vdots & \\vdots & h[3] \\\\ \\vdots   & \\vdots & \\vdots & \\vdots \\\\ h[N_y-1]   & \\vdots & \\vdots & \\vdots \\end{bmatrix}\n",
    "    \\begin{bmatrix} \n",
    "      x[0] \\\\ \\vdots \\\\ x[N_x-1] \\end{bmatrix}\n",
    "\\label{eq:conv2}\n",
    "$$\n",
    "\n",
    "This is similar to (1), but now the top triangle part is clipped off."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### a. Take the AR parameter $a =0.8$, take $N_x = 3$, $N_y = 20$, and generate the above data model in matlab."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "% add code here\r\n",
    "% [code]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### b. Using the SVD, what is the rank of $\\bf H$?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "% add code here\r\n",
    "% [code]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "If the (economy-size) SVD of $\\bf H$ is $\\bf H = \\bf U \\bf \\Sigma \\bf V^H$, then the\n",
    "   (economy-size) SVD of\n",
    "   $\\bf H^\\dagger$ is $\\bf H^\\dagger  = \\bf V \\bf \\Sigma^{-1} \\bf U^H$."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### c.Why do we refer to the economy-size SVD here?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "% type your answer here"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### d. Using the SVD properties, explain why $\\bf H^\\dagger \\bf H = \\bf I$ and $\\bf H \\bf H^\\dagger$ is a projection."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "% type your answer here"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "If $\\bf \\Sigma$ has entries that are (nearly) zero, then $\\bf \\Sigma^{-1}$ has\n",
    "   entries that go to infinity.  We define the pseudo-inverse of \n",
    "   $\\bf \\Sigma$ as\n",
    "   \n",
    "$$\n",
    "   \\bf \\Sigma = \\begin{bmatrix}\n",
    "      \\sigma_1 \\\\ \n",
    "        & \\sigma_2 \\\\\n",
    "\t&& 0 \\\\\n",
    "\t&&& 0 \\end{bmatrix}\n",
    "    \\qquad \\Rightarrow \\qquad\n",
    "   \\bf \\Sigma^\\dagger = \\begin{bmatrix}\n",
    "      1/\\sigma_1 \\\\ \n",
    "        & 1/\\sigma_2 \\\\\n",
    "\t&& 0 \\\\\n",
    "\t&&& 0 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "So, the nonzero entries are inverted, and the zero entries are kept zero.  (In practice, we specify a tolerance $\\epsilon$ and do not invert entries that are smaller than $\\epsilon$.)\n",
    "\n",
    "The (Moore-Penrose) pseudo-inverse of a matrix $\\bf X$ is then\n",
    "\n",
    "$$\n",
    "    \\bf X = \\bf U \\bf \\Sigma \\bf V^H \n",
    "    \\qquad \\Rightarrow \\qquad\n",
    "    \\bf X^\\dagger = \\bf V \\bf \\Sigma^\\dagger \\bf U^H \n",
    "$$\n",
    "\n",
    "This generalizes the left inverse that we saw before.  it satisfies 4\n",
    "properties:\n",
    "\n",
    "$$\n",
    "    \\bf X \\bf X^\\dagger \\bf X = \\bf X \\,,\\qquad\n",
    "    \\bf X^\\dagger \\bf X \\bf X^\\dagger = \\bf X^\\dagger\\,,\\qquad\n",
    "    \\bf X \\bf X^\\dagger = \\bf P_c \\,,\\qquad\n",
    "    \\bf X^\\dagger \\bf X = \\bf P_r \\,,\\qquad\n",
    "$$\n",
    "\n",
    "where $\\bf P_c$ is a projector onto the column span of $\\bf X$, and $\\bf P_r$\n",
    "    a projector onto its row span.\n",
    "\n",
    "In matlab, you say `Xi = pinv(X);`\n",
    "and you can specify a tolerance $\\epsilon$ as well.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### e. Compute the pseudo-inverse of $\\bf H$ in matlab."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "% add code here\r\n",
    "% [code]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### f. Compute $\\hat{\\bf x} = \\bf H^\\dagger \\bf y$. Do you get back the original $\\bf x$?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "% add code here\r\n",
    "% [code]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Sinusoids"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### a. Generate a time domain sequence $x[n] = e^{j \\omega n}$, for $\\omega = 0.2 \\pi$ and $n = 1, \\cdots, N$. Take $N=20$."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### b. Create a data matrix (Hankel matrix)\n",
    "\n",
    "$$\n",
    "       \\bf X = \\begin{bmatrix}\n",
    "          x[1] & x[2] & \\cdots & x[N-M+1]\\\\\n",
    "\t  x[2] & x[3] & \\vdots & \\vdots\\\\\n",
    "\t  x[3] & x[4] & \\vdots & \\vdots \\\\ \n",
    "\t  \\vdots &    &          & \\vdots \\\\\n",
    "\t  x[M] & x[M+1] & \\cdots & x[N] \n",
    "\t  \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Take $M=5$. You can use the Matlab function `hankel`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "% add code here\r\n",
    "% [code]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hankel matrices are constant along anti-diagonals. They are similar\n",
    "\tto Toeplitz matrices (by permuting columns or rows), so they also\n",
    "\tappear often in the context of shift-invariant systems."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### c. What is the rank of $\\bf X$?  (Use `svd` for this.)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "% add code here\r\n",
    "% [code]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### d. Can you theoretically explain the rank?  \n",
    "Look at the shift-invariance structure:\n",
    "$$\n",
    "      \\begin{bmatrix}\n",
    "      x[2] \\\\\n",
    "\t  x[3] \\\\\n",
    "\t  x[4] \\\\\n",
    "\t  \\vdots \\\\\n",
    "\t  x[M+1] \n",
    "\t  \\end{bmatrix}\n",
    "\t= \n",
    "      \\begin{bmatrix}\n",
    "          x[1] \\\\\n",
    "\t  x[2] \\\\\n",
    "\t  x[3] \\\\\n",
    "\t  \\vdots \\\\\n",
    "\t  x[M] \n",
    "\t  \\end{bmatrix}\n",
    "\t  e^{j\\omega}\n",
    "$$\n",
    "       \n",
    "This shows that the 2nd column is the same as the first, except for a\n",
    "       scaling. Extend this argument to the full matrix."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### e. Now, repeat: generate a time domain sequence $x[n] = \\sin(\\omega n)$, for $\\omega = 0.2 \\pi$ and $n = 1, \\cdots, N$. Take $N=20$. Construct the same matrix $\\bf X$, check the rank, explain."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "% add code here\r\n",
    "% [code]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    " ##### f. Let $y[n] = x[n] + e[n]$, where $e[n]$ is a small noise disturbance, e.g. `e = 0.1 * randn(1,20)`. Construct a Hankel matrix $\\bf Y$ from $y[n]$, and compute the SVD.  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "% add code here\r\n",
    "% [code]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Compare the singular values to those of $\\bf X$."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "% add code here\r\n",
    "% [code]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### g. To remove the noise, compute the SVD $\\bf Y = \\bf U \\bf \\Sigma\\bf V^H$, and set all small singular values of $\\bf Y$ equal to zero.  This gives an approximate matrix $\\bf{\\hat{\\Sigma}}$. Compute $\\bf{\\hat{Y}} =  \\bf U \\bf{\\hat{\\Sigma}}\\bf V^H$. This is called the Truncated SVD. \n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "% add code here\r\n",
    "% [code]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the first column and bottom row, regenerate a time-domain signal $\\hat{y}[n]$.  In a plot, compare $x[n]$, $y[n]$ and $\\hat{y}[n]$. How well did you remove the noise?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "% add code here\r\n",
    "% [code]"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Octave",
   "language": "octave",
   "name": "octave"
  },
  "language_info": {
   "file_extension": ".m",
   "help_links": [
    {
     "text": "GNU Octave",
     "url": "https://www.gnu.org/software/octave/support.html"
    },
    {
     "text": "Octave Kernel",
     "url": "https://github.com/Calysto/octave_kernel"
    },
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-octave",
   "name": "octave",
   "version": "4.2.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}